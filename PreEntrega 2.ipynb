{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1c3cc6-4097-4f07-95c0-5c600372db79",
   "metadata": {},
   "source": [
    "**Few Shoot Prompting**\n",
    "\n",
    "El Few-Shot Prompting aplicado a la gestión contextual de documentos representa una técnica avanzada de ingeniería de prompts donde se proporcionan ejemplos específicos y concisos para entrenar al modelo en la clasificación y selección del contexto más relevante. En lugar de procesar todos los documentos disponibles simultáneamente, este enfoque utiliza un conjunto reducido de ejemplos predefinidos que guían al modelo en la identificación del documento de referencia más apropiado para cada consulta. Esta metodología optimiza significativamente el consumo de tokens y mejora la precisión de las respuestas al establecer patrones claros de clasificación mediante ejemplos representativos, permitiendo una gestión más eficiente de los recursos computacionales y una mejor experiencia de usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0e40b-bc66-4f7a-b597-220473583933",
   "metadata": {},
   "source": [
    "**Lab**\n",
    "\n",
    "1. Import openAI dependences (load with conda install openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8208ba5e-7a39-4946-9126-9a1068e5b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acc308-4b33-4e32-aaae-2b226c3db72d",
   "metadata": {},
   "source": [
    "2. Use the API Key from openAI page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48d19dd-fe29-4624-b32a-33fef7e796c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key configurada: ***********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Add our API Key copied from openAI page\n",
    "openai.api_key = \"\" #Example -> dw-bQyr9128F49VJRNKAnST32lbkFJ2Zv4qEhWo4R0Xh6yrh15\n",
    "\n",
    "# Verificar que la API key está configurada\n",
    "print(f\"API Key configurada: {'*' * len(openai.api_key) if openai.api_key else 'No configurada'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57348a7-d0eb-4139-898d-b23268fa327b",
   "metadata": {},
   "source": [
    "3.1 Make a request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7c0322e-f852-496c-bbb7-6b6aed87de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Pregunta: ¿Cuál es el impacto del procesamiento de documentos en los recursos?\n",
      "\n",
      "Contexto utilizado: technical\n",
      "Respuesta: El procesamiento de documentos consume una cantidad significativa de tokens, lo que resulta en costos elevados y tiempos de respuesta más largos, afectando los recursos computacionales y económicos.\n",
      "\n",
      "==================================================\n",
      "Pregunta: ¿Qué debo hacer primero si veo un accidente?\n",
      "\n",
      "Contexto utilizado: safety\n",
      "Respuesta: Lo primero que debes hacer si ves un accidente es mantener la calma y evaluar la situación. Si hay peligro inmediato, evacua el área.\n",
      "\n",
      "==================================================\n",
      "Pregunta: ¿Cuánto tiempo toma llegar a nivel intermedio?\n",
      "\n",
      "Contexto utilizado: career\n",
      "Respuesta: Toma de 2 a 5 años llegar al nivel intermedio en el plan de desarrollo profesional de la empresa.\n",
      "\n",
      "==================================================\n",
      "Pregunta: ¿Cómo afecta este sistema a los costos operativos?\n",
      "\n",
      "Contexto utilizado: business\n",
      "Respuesta: La falta de un sistema que gestione eficientemente el contexto documental resulta en costos operativos elevados.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class ContextualAssistant:\n",
    "    def __init__(self, api_key: str = None):\n",
    "        if api_key:\n",
    "            openai.api_key = api_key\n",
    "            \n",
    "        # Diccionario de documentos de referencia\n",
    "        self.reference_docs = {\n",
    "            \"technical\": \"\"\"\n",
    "            Los asistentes de IA consumen una cantidad significativa de tokens al procesar grandes \n",
    "            volúmenes de información contextual, lo que resulta en costos elevados y tiempos de \n",
    "            respuesta más largos. Cuando un usuario realiza consultas que requieren el conocimiento \n",
    "            de múltiples documentos de referencia, el sistema típicamente debe procesar todos estos \n",
    "            documentos simultáneamente, lo que resulta ineficiente tanto en términos de recursos \n",
    "            computacionales como económicos.\n",
    "            \"\"\",\n",
    "            \n",
    "            \"business\": \"\"\"\n",
    "            Esta problemática es particularmente relevante en entornos empresariales, educativos\n",
    "            y de servicio al cliente, donde se requiere acceso rápido y preciso a información\n",
    "            específica contenida en diversos documentos. La falta de un sistema que gestione\n",
    "            eficientemente el contexto documental resulta en mayor consumo de recursos computacionales,\n",
    "            costos operativos elevados, tiempos de respuesta prolongados y menor precisión en las respuestas.\n",
    "            \"\"\",\n",
    "\n",
    "            \"safety\": \"\"\"\n",
    "            En caso de accidente laboral, siga inmediatamente este protocolo:\n",
    "            1. Mantenga la calma y evalúe la situación. Si hay peligro inmediato, evacue el área.\n",
    "            2. Para emergencias graves, llame inmediatamente al número de emergencias interno (ext. 555) o \n",
    "               al servicio médico de emergencia (911).\n",
    "            3. No mueva a una persona herida a menos que esté en peligro inmediato.\n",
    "            4. Localice el botiquín más cercano y proporcione primeros auxilios si está capacitado.\n",
    "            5. Notifique a su supervisor inmediato y al departamento de Recursos Humanos dentro de las \n",
    "               primeras 2 horas del incidente.\n",
    "            6. Complete el formulario de reporte de incidentes antes de finalizar su turno.\n",
    "            7. Coopere con la investigación de seguridad posterior al incidente.\n",
    "            \"\"\",\n",
    "\n",
    "            \"career\": \"\"\"\n",
    "            El plan de desarrollo profesional en nuestra empresa se estructura en tres niveles:\n",
    "            \n",
    "            Nivel Junior (0-2 años):\n",
    "            - Asignación de mentor senior\n",
    "            - Participación en proyectos supervisados\n",
    "            - Capacitación técnica mensual\n",
    "            \n",
    "            Nivel Intermedio (2-5 años):\n",
    "            - Liderazgo de proyectos pequeños\n",
    "            - Mentoría a nuevos empleados\n",
    "            - Especializaciones técnicas\n",
    "            \n",
    "            Nivel Senior (5+ años):\n",
    "            - Gestión de equipos y proyectos estratégicos\n",
    "            - Participación en decisiones departamentales\n",
    "            - Oportunidades de transferencia internacional\n",
    "            \n",
    "            Cada empleado tiene revisiones trimestrales para evaluar su progreso y ajustar su plan de desarrollo.\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        # Ejemplos para clasificación\n",
    "        self.classification_examples = [\n",
    "            {\n",
    "                \"query\": \"¿Cómo afecta el consumo de tokens al rendimiento?\",\n",
    "                \"context\": \"technical\",\n",
    "                \"explanation\": \"Esta pregunta se refiere a aspectos técnicos del procesamiento.\"\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"¿Qué impacto tiene en los costos operativos?\",\n",
    "                \"context\": \"business\",\n",
    "                \"explanation\": \"Esta pregunta se relaciona con aspectos empresariales y económicos.\"\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"¿Qué debo hacer si alguien se lesiona en el trabajo?\",\n",
    "                \"context\": \"safety\",\n",
    "                \"explanation\": \"Esta pregunta se relaciona con protocolos de seguridad y accidentes.\"\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"¿Cuáles son las oportunidades de crecimiento para un desarrollador junior?\",\n",
    "                \"context\": \"career\",\n",
    "                \"explanation\": \"Esta pregunta se relaciona con desarrollo profesional y carrera.\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def classify_query(self, query: str) -> str:\n",
    "        prompt = \"Clasifica la siguiente consulta en una de estas categorías: 'technical', 'business', 'safety', o 'career'.\\n\\nEjemplos:\\n\"\n",
    "        \n",
    "        for example in self.classification_examples:\n",
    "            prompt += f\"\\nConsulta: {example['query']}\\n\"\n",
    "            prompt += f\"Categoría: {example['context']}\\n\"\n",
    "            prompt += f\"Explicación: {example['explanation']}\\n\"\n",
    "            \n",
    "        prompt += f\"\\nNueva consulta: {query}\\nCategoría:\"\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=50,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        category = response.choices[0].message.content.strip().lower()\n",
    "        \n",
    "        if 'technical' in category:\n",
    "            return 'technical'\n",
    "        elif 'safety' in category:\n",
    "            return 'safety'\n",
    "        elif 'career' in category:\n",
    "            return 'career'\n",
    "        else:\n",
    "            return 'business'\n",
    "\n",
    "    def get_response(self, query: str) -> Tuple[str, str]:\n",
    "        context_type = self.classify_query(query)\n",
    "        selected_context = self.reference_docs[context_type]\n",
    "        \n",
    "        prompt = f\"\"\"Contexto: {selected_context}\n",
    "\n",
    "Consulta: {query}\n",
    "\n",
    "Genera una respuesta basada únicamente en la información proporcionada en el contexto anterior.\"\"\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip(), context_type\n",
    "\n",
    "    def single_response(self, query: str):\n",
    "        response, context_used = self.get_response(query)\n",
    "        print(f\"\\nContexto utilizado: {context_used}\")\n",
    "        print(f\"Respuesta: {response}\")\n",
    "        return response, context_used\n",
    "\n",
    "# Pruebas\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = ContextualAssistant()\n",
    "    \n",
    "    preguntas_prueba = [\n",
    "        \"¿Cuál es el impacto del procesamiento de documentos en los recursos?\",\n",
    "        \"¿Qué debo hacer primero si veo un accidente?\",\n",
    "        \"¿Cuánto tiempo toma llegar a nivel intermedio?\",\n",
    "        \"¿Cómo afecta este sistema a los costos operativos?\"\n",
    "    ]\n",
    "    \n",
    "    for pregunta in preguntas_prueba:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Pregunta: {pregunta}\")\n",
    "        assistant.single_response(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42e959-937c-497a-b875-270f312da943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab1f09-f7ef-4f56-a6de-ca63b1946708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
